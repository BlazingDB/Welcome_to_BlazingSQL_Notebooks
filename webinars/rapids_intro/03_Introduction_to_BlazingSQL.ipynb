{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU-Accelerated Data Science: Introduction to Blazing SQL and RAPIDS\n",
    "\n",
    "Programming on GPUs can be intimidating. In the past it required a solid knowledge of C++ and CUDA, and the ability to think *in parallel*. Today, with [RAPIDS](https://rapids.ai) and [BlazingSQL](https://blazingsql.com), you can get started using the immense power of GPUs in no time. And all of that with minimal code changes: whether you use PyData ecosystem tools like pandas or Scikit-Learn, or are more familiar with SQL, RAPIDS and BlazingSQL will enable you to achieve immense speedups by offloading all the computations to GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "First, of course, let's import the tools that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import blazingsql as bsql\n",
    "import s3fs\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from IPython.display import HTML\n",
    "from bokeh.io import output_file, show\n",
    "from bokeh.models import ColumnDataSource, GMapOptions, LabelSet\n",
    "from bokeh.plotting import gmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BlazingContext`\n",
    "You must establish a `BlazingContext` to connect to a BlazingSQL instance to create tables, run queries, and basically do anything with BlazingSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = bsql.BlazingContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `BlazingContext` is an entrypoint for all things Blazing. In this particular instance we start the `BlazingContext` with default parameters but there are many ways to customize it and expand its capablities.\n",
    "\n",
    "|Argument|Required|Description|Defaults|\n",
    "|:-------|:------:|:----------|-------:|\n",
    "allocator|      No|Options are \"default\", \"managed\". Where \"managed\" uses Unified Virtual Memory (UVM) and may use system memory if GPU memory runs out, or \"existing\" where it assumes you have already set the rmm allocator and therefore does not initialize it (this is for advanced users.).|\"managed\"\n",
    "dask_client|No|The dask client used for communicating with other nodes. This is only necessary for running BlazingSQL with multiple nodes.|None\n",
    "enable_logging|No|If set to True the memory allocator logging will be enabled, but can negatively impact performance. This is for advanced users.|False\n",
    "initial_pool_size|No|Initial size of memory pool in bytes (if pool=True). If None, it will default to using half of the GPU memory.|None\n",
    "pool|No|If True, allocate a memory pool in the beginning. This can greatly improve performance.|False\n",
    "network_interface|No|Network interface used for communicating with the dask-scheduler. See note below.|'eth0'\n",
    "config_options|No|A dictionary for setting certain parameters in the engine.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reading and querying\n",
    "\n",
    "There are two ways to load and query data using tools from the RAPIDS ecosystem: load directly into memory using `cudf` or `.create_table()` using `BlazingContext`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_data_path = 's3://bsql/data/air_transport/flight_ontime_2020-0[1-5].parquet'\n",
    "s3 = s3fs.S3FileSystem(anon=True)\n",
    "files = [f's3://{f}' for f in s3.glob(flight_data_path)]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cuDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "flights = []\n",
    "\n",
    "for f in files:\n",
    "    flights.append(cudf.read_parquet(f, storage_options={'anon': True}))\n",
    "    \n",
    "flights = cudf.concat(flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total number of flights in the dataset: {len(flights):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BlazingSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = bc.s3(\n",
    "    'bsql'\n",
    "    , bucket_name = 'bsql'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.create_table('air_transport', files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bc.sql('SELECT * FROM air_transport LIMIT 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total number of flights in the dataset: {bc.sql(\"SELECT COUNT(*) AS CNT FROM air_transport\")[\"CNT\"].iloc[0]:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `BlazingContext` returns a cuDF DataFrame object so we have access to the same API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_df = bc.sql('SELECT * FROM air_transport LIMIT 5')\n",
    "type(bc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Airlines and airports data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_path = 's3://bsql/data/air_transport/airports.csv'\n",
    "airlines_path = 's3://bsql/data/air_transport/airlines.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_dtypes = OrderedDict([\n",
    "      ('Airport ID', 'int64')\n",
    "    , ('Name', 'str')\n",
    "    , ('City', 'str')\n",
    "    , ('Country', 'str')\n",
    "    , ('IATA', 'str')\n",
    "    , ('ICAO', 'str')\n",
    "    , ('Latitude', 'float64')\n",
    "    , ('Longitude', 'float64')\n",
    "    , ('Altitude', 'int64')\n",
    "    , ('Timezone', 'str')\n",
    "    , ('DST', 'str')\n",
    "    , ('Type', 'str')\n",
    "    , ('Source', 'str')\n",
    "])\n",
    "\n",
    "airports = cudf.read_csv(\n",
    "    airports_path\n",
    "    , names=list(airports_dtypes.keys())\n",
    "    , dtype=list(airports_dtypes.values())\n",
    "    , storage_options={'anon': True}\n",
    ")\n",
    "airports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_dtypes = OrderedDict([\n",
    "    ('Airline ID', 'int64')\n",
    "    , ('Name', 'str')\n",
    "    , ('Alias', 'str')\n",
    "    , ('IATA', 'str')\n",
    "    , ('ICAO', 'str')\n",
    "    , ('Callsign', 'str')\n",
    "    , ('Country', 'str')\n",
    "    , ('Active', 'str')\n",
    "])\n",
    "\n",
    "airlines = cudf.read_csv(\n",
    "    airlines_path\n",
    "    , names=list(airlines_dtypes.keys())\n",
    "    , dtype=list(airlines_dtypes.values())\n",
    "    , storage_options={'anon': True}\n",
    ")\n",
    "airlines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create BlazingSQL tables directly from cuDF DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.create_table('airports', airports)\n",
    "bc.create_table('airlines', airlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can use it to query and join these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bc.sql('''\n",
    "    SELECT A.FL_DATE\n",
    "        , A.OP_UNIQUE_CARRIER\n",
    "        , B.Name AS CARRIER_NAME\n",
    "        , A.ORIGIN\n",
    "        , C.Name AS ORIGIN_NAME\n",
    "        , C.City AS ORIGIN_CITY\n",
    "        , A.DEST\n",
    "        , D.Name AS DEST_NAME\n",
    "        , D.City AS DEST_CITY\n",
    "    FROM air_transport AS A\n",
    "    LEFT OUTER JOIN airlines AS B\n",
    "        ON A.OP_UNIQUE_CARRIER = B.IATA\n",
    "    LEFT OUTER JOIN airports AS C\n",
    "        ON A.ORIGIN = C.IATA\n",
    "    LEFT OUTER JOIN airports AS D\n",
    "        ON A.DEST = D.IATA\n",
    "    LIMIT 4\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The beauty of the ecosystem, and BlazingSQL in particular, comes from the direct inter-operability with RAPIDS: we can create tables from cudf and any file format supported by cuDF, either local or remote; you can register buckets from `s3` and `gcp` with the `BlazingContext` with support for Azure coming in future releases. So, as easily, we could simply create the tables directly from files and trivially write code that returns a cuDF DataFrame by joining Parquet and CSV files in just couple of lines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.create_table('airports_table', airports_path, names=list(airports_dtypes.keys()), dtype=list(airports_dtypes.values()))\n",
    "bc.create_table('airlines_table', airlines_path, names=list(airlines_dtypes.keys()), dtype=list(airlines_dtypes.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bc.sql('''\n",
    "    SELECT A.FL_DATE\n",
    "        , A.OP_UNIQUE_CARRIER\n",
    "        , B.Name AS CARRIER_NAME\n",
    "        , A.ORIGIN\n",
    "        , C.Name AS ORIGIN_NAME\n",
    "        , C.City AS ORIGIN_CITY\n",
    "        , A.DEST\n",
    "        , D.Name AS DEST_NAME\n",
    "        , D.City AS DEST_CITY\n",
    "    FROM air_transport AS A                // READING FROM PARQUET\n",
    "    LEFT OUTER JOIN airlines AS B\n",
    "        ON A.OP_UNIQUE_CARRIER = B.IATA\n",
    "    LEFT OUTER JOIN airports_table AS C    // READING FROM CSV\n",
    "        ON A.ORIGIN = C.IATA\n",
    "    LEFT OUTER JOIN airports_table AS D    // READING FROM CSV\n",
    "        ON A.DEST = D.IATA\n",
    "    LIMIT 4\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "(\n",
    "    flights[['FL_DATE', 'OP_UNIQUE_CARRIER', 'ORIGIN', 'DEST']]\n",
    "    .merge(airlines[['IATA', 'Name']], left_on='OP_UNIQUE_CARRIER', right_on='IATA')\n",
    "    .rename(columns={'Name': 'CARRIER_NAME'})\n",
    "    .drop(columns=['IATA'])\n",
    "    .merge(airports[['IATA', 'Name', 'City']], left_on='ORIGIN', right_on='IATA')\n",
    "    .rename(columns={'Name': 'ORIGIN_NAME', 'City': 'ORIGIN_CITY'})\n",
    "    .drop(columns=['IATA'])\n",
    "    .merge(airports[['IATA', 'Name', 'City']], left_on='DEST', right_on='IATA')\n",
    "    .rename(columns={'Name': 'DEST_NAME', 'City': 'DEST_CITY'})\n",
    "    .drop(columns=['IATA'])\n",
    ").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. How many unique airports are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(flights[\"ORIGIN\"].unique())} distinct airports in the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {bc.sql(\"SELECT COUNT(DISTINCT ORIGIN) AS CNT FROM air_transport\")[\"CNT\"][0]} distinct airports in the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. How many flights were delayed and departed early? What is the distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(flights[flights[\"DEP_DELAY\"] > 0]):,} flights were delayed and {len(flights[flights[\"DEP_DELAY\"] <= 0]):,} left on time or early')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculate the distribution\n",
    "n_bins = 100\n",
    "\n",
    "delays = flights[flights['DEP_DELAY'] >  0]['DEP_DELAY']\n",
    "ontime = flights[flights['DEP_DELAY'] <= 0]['DEP_DELAY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "del_bins = np.array([i * 15 for i in range(0, n_bins)], dtype='float64')\n",
    "delays_binned = delays.digitize(del_bins)\n",
    "delays_histogram = delays_binned.groupby().count() / len(delays)\n",
    "(\n",
    "    delays_histogram\n",
    "    .set_index(del_bins[delays_histogram.index.to_array()-1])\n",
    "    .to_pandas()\n",
    "    .plot(kind='bar', figsize=(20,9), ylim=[0,1.0], title='Delayed departure distribution')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ontime_bins = np.array([i * (-1) for i in range(n_bins,0,-1)], dtype='float64')\n",
    "ontime_binned = ontime.digitize(ontime_bins)\n",
    "ontime_histogram = ontime_binned.groupby().count() / len(ontime)\n",
    "(\n",
    "    ontime_histogram\n",
    "    .set_index(ontime_bins[ontime_histogram.index.to_array()-1])\n",
    "    .to_pandas()\n",
    "    .plot(kind='bar', figsize=(20,9), ylim=[0,1.0], title='Early departure distribution')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What are the top 10 airlines and airports with most delays and at least 1000 flights? What is average delay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays = flights[flights['DEP_DELAY'] >  0][['DEP_DELAY', 'ORIGIN', 'DEST', 'OP_UNIQUE_CARRIER']]\n",
    "ontime = flights[flights['DEP_DELAY'] <= 0][['DEP_DELAY', 'ORIGIN', 'DEST', 'OP_UNIQUE_CARRIER']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.create_table('delays', delays)\n",
    "bc.create_table('ontime', ontime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bc.sql('''\n",
    "    SELECT A.ORIGIN\n",
    "        , B.Name AS ORIGIN_Airport\n",
    "        , B.City AS ORIGIN_City\n",
    "        , B.Country AS ORIGIN_Country\n",
    "        , COUNT(*) AS DELAY_CNT\n",
    "        , AVG(DEP_DELAY) AS AVG_DELAY\n",
    "    FROM delays AS A\n",
    "    LEFT OUTER JOIN airports AS B\n",
    "        ON A.ORIGIN = B.IATA\n",
    "    GROUP BY A.ORIGIN\n",
    "        , B.Name\n",
    "        , B.City\n",
    "        , B.Country\n",
    "    HAVING COUNT(*) > 1000\n",
    "    ORDER BY AVG(DEP_DELAY) DESC\n",
    "    LIMIT 10\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bc.sql('''\n",
    "    SELECT A.DEST\n",
    "        , B.Name AS DEST_Airport\n",
    "        , B.City AS DEST_City\n",
    "        , B.Country AS DEST_Country\n",
    "        , COUNT(*) AS DELAY_CNT\n",
    "        , AVG(DEP_DELAY) AS AVG_DELAY\n",
    "    FROM delays AS A\n",
    "    LEFT OUTER JOIN airports AS B\n",
    "        ON A.DEST = B.IATA\n",
    "    GROUP BY A.DEST\n",
    "        , B.Name\n",
    "        , B.City\n",
    "        , B.Country\n",
    "    HAVING COUNT(*) > 1000\n",
    "    ORDER BY AVG(DEP_DELAY) DESC\n",
    "    LIMIT 10\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bc.sql('''\n",
    "    SELECT A.OP_UNIQUE_CARRIER AS CARRIER\n",
    "        , B.Name AS CARRIER_Name\n",
    "        , B.Country AS CARRIER_Country\n",
    "        , COUNT(*) AS DELAY_CNT\n",
    "        , AVG(DEP_DELAY) AS AVG_DELAY\n",
    "    FROM delays AS A\n",
    "    LEFT OUTER JOIN airlines AS B\n",
    "        ON A.OP_UNIQUE_CARRIER = B.IATA\n",
    "    GROUP BY A.OP_UNIQUE_CARRIER\n",
    "        , B.Name\n",
    "        , B.Country\n",
    "    HAVING COUNT(*) > 1000\n",
    "    ORDER BY AVG(DEP_DELAY) DESC\n",
    "    LIMIT 10\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most punctual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bc.sql('''\n",
    "    SELECT A.ORIGIN\n",
    "        , B.Name AS ORIGIN_Airport\n",
    "        , B.City AS ORIGIN_City\n",
    "        , B.Country AS ORIGIN_Country\n",
    "        , COUNT(*) AS ONTIME_CNT\n",
    "        , AVG(DEP_DELAY) AS AVG_ONTIME\n",
    "    FROM ontime AS A\n",
    "    LEFT OUTER JOIN airports AS B\n",
    "        ON A.ORIGIN = B.IATA\n",
    "    GROUP BY A.ORIGIN\n",
    "        , B.Name\n",
    "        , B.City\n",
    "        , B.Country\n",
    "    HAVING COUNT(*) > 1000\n",
    "    ORDER BY AVG(DEP_DELAY) DESC\n",
    "    LIMIT 10\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bc.sql('''\n",
    "    SELECT A.DEST\n",
    "        , B.Name AS DEST_Airport\n",
    "        , B.City AS DEST_City\n",
    "        , B.Country AS DEST_Country\n",
    "        , COUNT(*) AS ONTIME_CNT\n",
    "        , AVG(DEP_DELAY) AS AVG_ONTIME\n",
    "    FROM ontime AS A\n",
    "    LEFT OUTER JOIN airports AS B\n",
    "        ON A.DEST = B.IATA\n",
    "    GROUP BY A.DEST\n",
    "        , B.Name\n",
    "        , B.City\n",
    "        , B.Country\n",
    "    HAVING COUNT(*) > 1000\n",
    "    ORDER BY AVG(DEP_DELAY) DESC\n",
    "    LIMIT 10\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bc.sql('''\n",
    "    SELECT A.OP_UNIQUE_CARRIER AS CARRIER\n",
    "        , B.Name AS CARRIER_Name\n",
    "        , B.Country AS CARRIER_Country\n",
    "        , AVG(DEP_DELAY) AS AVG_ONTIME\n",
    "    FROM ontime AS A\n",
    "    LEFT OUTER JOIN airlines AS B\n",
    "        ON A.OP_UNIQUE_CARRIER = B.IATA\n",
    "    GROUP BY A.OP_UNIQUE_CARRIER\n",
    "        , B.Name\n",
    "        , B.Country\n",
    "    HAVING COUNT(*) > 1000\n",
    "    ORDER BY AVG(DEP_DELAY) DESC\n",
    "    LIMIT 10\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates, strings, oh my...\n",
    "\n",
    "A common misconception is that GPUs are useful for only numeric computations. However, with RAPIDS and BlazingSQL you can perform operations on dates and strings with ease and at GPU's speeds!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flights per month and day of week\n",
    "\n",
    "Even though we already have columns like `YEAR` or `MONTH`, let's calculate these values ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "flights['FL_DATE'] = flights['FL_DATE'].astype('datetime64[ms]')\n",
    "dated = flights[['FL_DATE', 'OP_UNIQUE_CARRIER']]\n",
    "dated['YEAR'] = dated['FL_DATE'].dt.year\n",
    "dated['MONTH'] = dated['FL_DATE'].dt.month\n",
    "dated['DAY'] = dated['FL_DATE'].dt.day\n",
    "dated['DOW'] = dated['FL_DATE'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "(\n",
    "    dated\n",
    "    .groupby(['YEAR','MONTH'])\n",
    "    .agg({'FL_DATE': 'count'})\n",
    "    .to_pandas()\n",
    "    .plot(kind='bar', figsize=(12,9), title='Total flights per month')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "(\n",
    "    dated\n",
    "    .groupby(['MONTH','DAY', 'DOW'])\n",
    "    .agg({'FL_DATE': 'count'})\n",
    "    .reset_index()\n",
    "    .groupby(['DOW'])\n",
    "    .agg({'FL_DATE': 'mean'})\n",
    "    .to_pandas()\n",
    "    .plot(kind='bar', figsize=(12,9), title='Average number of flights per weekday')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
